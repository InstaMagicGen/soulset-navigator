// /api/analyze â€” Edge Function (Vercel)
export const config = { runtime: "edge" };

const SYSTEM_PROMPT = `
Tu es "The Soulset Navigator", une voix douce et poÃ©tique alignÃ©e avec la marque SoulsetJourney.
Ta mission : clarifier un dilemme en 4 sections (FR), concises mais profondes :
1) ðŸŒ« Lecture Ã©nergÃ©tique â€” ce que rÃ©vÃ¨le le dilemme (conflits internes, besoins de l'Ã¢me)
2) ðŸªž Clarity Insight â€” une prise de conscience concrÃ¨te, sans blÃ¢mer
3) ðŸ•¯ Rituel â€” micro-pratique rÃ©alisable en < 5 minutes (respiration 4â€“6â€“8, Ã©criture, marche consciente)
4) ðŸ—£ Parole de guidance â€” courte phrase/mantra au ton SoulsetJourney

Contraintes :
- Ton doux, rassurant, non-moraliste (images lumineuses : ciel, horizon, souffle)
- 5 Ã  8 lignes max
- Pas d'avis mÃ©dical, financier ou juridique
- Tu peux proposer 1 "Option produit" en 5 mots max si pertinent, format : Option produit : <nom>
`;

export default async function handler(req) {
  if (req.method !== "POST") {
    return new Response(JSON.stringify({ ok:false, error:"Method not allowed" }), { status: 405 });
  }

  // Lire le corps JSON (robuste) et accepter text|dilemma
  let bodyIn;
  try { bodyIn = await req.json(); }
  catch { return new Response(JSON.stringify({ ok:false, error:"Invalid JSON body" }), { status: 400 }); }

  const userText = (bodyIn?.text ?? bodyIn?.dilemma ?? "").toString().trim();
  if (!userText) {
    return new Response(JSON.stringify({ ok:false, error:"Missing text/dilemma" }), { status: 400 });
  }

  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    return new Response(JSON.stringify({ ok:false, error:"Missing OPENAI_API_KEY" }), { status: 500 });
  }

  // Messages pour Chat Completions
  const messages = [
    { role: "system", content: SYSTEM_PROMPT },
    { role: "user", content: `Dilemme : ${userText}` }
  ];

  // Essaie d'abord gpt-4o-mini (rapide/Ã©co), sinon gpt-4o en fallback si besoin
  const modelsToTry = ["gpt-4o-mini", "gpt-4o"];

  for (const model of modelsToTry) {
    try {
      const r = await fetch("https://api.openai.com/v1/chat/completions", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${apiKey}`
        },
        body: JSON.stringify({
          model,
          messages,
          temperature: 0.8
        })
      });

      const data = await r.json();

      if (!r.ok) {
        // Log cÃ´tÃ© serveur pour debug dans Runtime Logs
        console.log("OpenAI chat error:", model, data);
        // essaie le modÃ¨le suivant
        continue;
      }

      const out =
        data?.choices?.[0]?.message?.content?.trim() || "";

      if (!out) {
        console.log("Empty completion content for model:", model, data);
        continue;
      }

      // Suggestion produit simple (heuristique)
      let product = null;
      const low = userText.toLowerCase();
      if (/(stress|dormi|sommeil|anx|angoisse)/.test(low)) product = "Diffuseur â€˜Lune Zenâ€™";
      else if (/(dispers|choisir|trop d'options|focus)/.test(low)) product = "Lampe dâ€™ambiance â€˜Focusâ€™";
      else if (/(creativ|inspiration|idÃ©e|idee)/.test(low)) product = "ASTRO-MIND Projector";

      return new Response(
        JSON.stringify({ ok:true, text: out, markdown: out, result: out, modelUsed: model, product }),
        { status: 200, headers: { "Content-Type": "application/json" } }
      );
    } catch (e) {
      console.log("Server fetch error:", model, e?.message || e);
      // essaie le modÃ¨le suivant
      continue;
    }
  }

  // Si aucun modÃ¨le nâ€™a produit de texte :
  return new Response(JSON.stringify({ ok:false, error:"No output generated by models" }), { status: 500 });
}
